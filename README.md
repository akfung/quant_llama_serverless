# quant_llama_serverless
Serverless GPU Llama2 Deployment
